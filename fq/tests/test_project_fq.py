#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import subprocess
import tempfile
from pathlib import Path
from unittest.mock import MagicMock, Mock, mock_open, patch

import numpy as np
import pandas as pd
import pytest

# å‡è®¾ä¸»æ¨¡å—åä¸º fastq_processor
from fq.project_fq import (
    FASTQ_EXTENSIONS,
    READ_TYPE_PATTERNS,
    FastqProcessor,
    ScriptRunner,
    log_statistics,
    validate_sample_info,
    write_nextflow_input,
)


class TestFastqProcessor:
    """æµ‹è¯•FastqProcessorç±»"""

    def setup_method(self):
        """æ¯ä¸ªæµ‹è¯•æ–¹æ³•å‰çš„è®¾ç½®"""
        self.temp_dir = Path(tempfile.mkdtemp())
        self.processor = FastqProcessor(self.temp_dir)

    def teardown_method(self):
        """æ¯ä¸ªæµ‹è¯•æ–¹æ³•åçš„æ¸…ç†"""
        import shutil

        shutil.rmtree(self.temp_dir, ignore_errors=True)

    def test_init_valid_directory(self):
        """æµ‹è¯•æœ‰æ•ˆç›®å½•åˆå§‹åŒ–"""
        assert self.processor.base_dir == self.temp_dir
        assert self.processor.base_dir.exists()

    def test_init_invalid_directory(self):
        """æµ‹è¯•æ— æ•ˆç›®å½•åˆå§‹åŒ–"""
        invalid_dir = Path("/nonexistent/directory")
        with pytest.raises(FileNotFoundError, match="åŸºç¡€ç›®å½•ä¸å­˜åœ¨"):
            FastqProcessor(invalid_dir)

    def test_determine_read_type(self):
        """æµ‹è¯•è¯»å–ç±»å‹è¯†åˆ«"""
        test_cases = [
            ("sample_combined_R1.fastq.gz", "R1"),
            ("sample_combined_R2.fastq.gz", "R2"),
            ("sample_R1.fastq.gz", "R1"),
            ("sample_R2.fastq.gz", "R2"),
            ("sample_1.fastq.gz", "R1"),
            ("sample_2.fastq.gz", "R2"),
            ("sample_unknown.fastq.gz", None),
        ]

        for filename, expected in test_cases:
            result = self.processor._determine_read_type(filename)
            assert result == expected, f"Failed for {filename}"

    @patch("pathlib.Path.exists", return_value=True)
    @patch("pathlib.Path.glob")
    def test_parse_fastq_filename_fq_extension(self, mock_glob, mock_exists):
        processor = FastqProcessor(Path("/fake/base"))

        # åˆ›å»º FASTQ æ–‡ä»¶ mock
        mock_fastq1 = Mock()
        mock_fastq1.name = "sample_1.fq.gz"
        mock_fastq1.absolute.return_value = Path("/path/to/sample_1.fq.gz")

        mock_fastq2 = Mock()
        mock_fastq2.name = "sample_2.fq.gz"
        mock_fastq2.absolute.return_value = Path("/path/to/sample_2.fq.gz")

        # è®¾ç½® glob çš„ side effect
        def glob_side_effect(pattern):
            if pattern == "*.fastq.gz":
                return []
            elif pattern == "*.fq.gz":
                return [mock_fastq1, mock_fastq2]
            return []

        mock_glob.side_effect = glob_side_effect

        sample_path = Path("Sample-LIB002")
        result = processor.parse_fastq_filename(sample_path)

        expected = [
            {
                "libid": "LIB002",
                "read_type": "R1",
                "path": "/path/to/sample_1.fq.gz",
            },
            {
                "libid": "LIB002",
                "read_type": "R2",
                "path": "/path/to/sample_2.fq.gz",
            },
        ]
        assert result == expected

    @patch("pathlib.Path.exists")
    def test_parse_fastq_filename_nonexistent_path(self, mock_exists):
        """æµ‹è¯•ä¸å­˜åœ¨çš„è·¯å¾„"""
        mock_exists.return_value = False

        sample_path = Path("Sample-LIB001")
        result = self.processor.parse_fastq_filename(sample_path)

        assert result == []

    @patch("pathlib.Path.exists")
    @patch("pathlib.Path.glob")
    @patch("tqdm.tqdm")
    def test_build_libid_fastq_map(self, mock_tqdm, mock_glob, mock_exists):
        """æµ‹è¯•æ„å»ºlibidæ˜ å°„"""
        mock_exists.return_value = True

        # æ¨¡æ‹ŸSampleç›®å½•
        mock_sample_dir = Mock()
        mock_sample_dir.name = "Sample-LIB001"
        mock_glob.return_value = [mock_sample_dir]
        mock_tqdm.return_value = [mock_sample_dir]

        # æ¨¡æ‹Ÿparse_fastq_filenameè¿”å›
        with patch.object(self.processor, "parse_fastq_filename") as mock_parse:
            mock_parse.return_value = [
                {"libid": "LIB001", "read_type": "R1", "path": "/path/R1.fastq.gz"}
            ]

            result = self.processor.build_libid_fastq_map(Path("test_path"))

            assert isinstance(result, pd.DataFrame)
            assert len(result) == 1
            assert result.iloc[0]["libid"] == "LIB001"

    @patch("pathlib.Path.exists")
    @patch("pandas.read_table")
    def test_read_or_build_config_existing_file(self, mock_read_table, mock_exists):
        """æµ‹è¯•è¯»å–å·²å­˜åœ¨çš„é…ç½®æ–‡ä»¶"""
        mock_exists.return_value = True

        # æ¨¡æ‹Ÿé…ç½®æ–‡ä»¶å†…å®¹
        mock_df = pd.DataFrame(
            {
                "libid": ["LIB001"],
                "read_type": ["R1"],
                "path": ["/path/to/file.fastq.gz"],
            }
        )
        mock_read_table.return_value = mock_df

        result = self.processor.read_or_build_config(Path("test_dir"))

        assert isinstance(result, pd.DataFrame)
        assert len(result) == 1
        mock_read_table.assert_called_once()

    @patch("pathlib.Path.exists")
    @patch("pandas.read_table")
    def test_read_or_build_config_rebuild_needed(self, mock_read_table, mock_exists):
        """æµ‹è¯•éœ€è¦é‡å»ºé…ç½®æ–‡ä»¶çš„æƒ…å†µ"""
        mock_exists.return_value = True

        # æ¨¡æ‹Ÿè¯»å–å¤±è´¥
        mock_read_table.side_effect = Exception("è¯»å–å¤±è´¥")

        with patch.object(self.processor, "build_libid_fastq_map") as mock_build:
            mock_build.return_value = pd.DataFrame(
                {
                    "libid": ["LIB001"],
                    "read_type": ["R1"],
                    "path": ["/path/to/file.fastq.gz"],
                }
            )

            result = self.processor.read_or_build_config(Path("test_dir"))

            assert isinstance(result, pd.DataFrame)
            mock_build.assert_called_once()

    @patch("pathlib.Path.glob")
    @patch("tqdm.tqdm")
    def test_load_config(self, mock_tqdm, mock_glob):
        """æµ‹è¯•åŠ è½½é…ç½®"""
        # æ¨¡æ‹Ÿç›®å½•ç»“æ„
        mock_date_dir = Mock()
        mock_date_dir.is_dir.return_value = True
        mock_tcwl_dir = Mock()
        mock_tcwl_dir.name = "tcwl-test"
        mock_date_dir.glob.return_value = [mock_tcwl_dir]

        mock_glob.return_value = [mock_date_dir]  # base_dir.glob("20*")
        mock_tqdm.return_value = [mock_tcwl_dir]

        with patch.object(self.processor, "read_or_build_config") as mock_read:
            mock_read.return_value = pd.DataFrame(
                {
                    "libid": ["LIB001"],
                    "read_type": ["R1"],
                    "path": ["/path/to/file.fastq.gz"],
                }
            )

            result = self.processor.load_config(np.array(["tcwl-test"]))

            assert isinstance(result, pd.DataFrame)
            assert len(result) == 1


class TestScriptRunner:
    """æµ‹è¯•ScriptRunnerç±»"""

    def test_merge_or_link_command_single_file(self):
        """æµ‹è¯•å•æ–‡ä»¶å‘½ä»¤ç”Ÿæˆ"""
        fq_list = ["/path/to/file1.fastq.gz"]
        output_name = "output.fastq.gz"

        result = ScriptRunner.merge_or_link_command(fq_list, output_name)
        expected = "cp /path/to/file1.fastq.gz output.fastq.gz"

        assert result == expected

    def test_merge_or_link_command_multiple_files(self):
        """æµ‹è¯•å¤šæ–‡ä»¶å‘½ä»¤ç”Ÿæˆ"""
        fq_list = ["/path/to/file1.fastq.gz", "/path/to/file2.fastq.gz"]
        output_name = "output.fastq.gz"

        result = ScriptRunner.merge_or_link_command(fq_list, output_name)
        expected = (
            "cat /path/to/file1.fastq.gz /path/to/file2.fastq.gz > output.fastq.gz"
        )

        assert result == expected

    @patch("subprocess.run")
    def test_run_script_success(self, mock_run):
        """æµ‹è¯•è„šæœ¬æ‰§è¡ŒæˆåŠŸ"""
        mock_run.return_value = Mock(returncode=0)

        script_path = Path("test_script.sh")
        success, message = ScriptRunner.run_script(script_path)

        assert success is True
        assert "æˆåŠŸ" in message
        mock_run.assert_called_once_with(
            ["bash", str(script_path)], check=True, capture_output=True, text=True
        )

    @patch("subprocess.run")
    def test_run_script_failure(self, mock_run):
        """æµ‹è¯•è„šæœ¬æ‰§è¡Œå¤±è´¥"""
        mock_run.side_effect = subprocess.CalledProcessError(
            1, "bash", stderr="Error message"
        )

        script_path = Path("test_script.sh")
        success, message = ScriptRunner.run_script(script_path)

        assert success is False
        assert "å¤±è´¥" in message
        assert "Error message" in message

    @patch("tqdm.tqdm")
    @patch("concurrent.futures.ThreadPoolExecutor")
    @patch("subprocess.run")  # ğŸ‘ˆ æœ€å patch çš„ï¼Œæœ€å…ˆä¼ å…¥
    @patch("pathlib.Path.glob")
    def test_run_scripts_in_parallel(
        self, mock_glob, mock_run, mock_executor, mock_tqdm
    ):
        """æµ‹è¯•å¹¶è¡Œæ‰§è¡Œè„šæœ¬"""
        # æ¨¡æ‹Ÿè„šæœ¬åˆ—è¡¨
        script1 = Path("script1.sh")
        script2 = Path("script2.sh")
        mock_glob.return_value = [script1, script2]

        # mock run() æˆåŠŸå’Œå¤±è´¥
        def run_side_effect(args, check, capture_output, text):
            if "script1.sh" in args:
                return Mock(returncode=0, stdout="done")
            else:
                raise subprocess.CalledProcessError(1, args, stderr="Error")

        mock_run.side_effect = run_side_effect

        # ThreadPoolExecutor æ¨¡æ‹Ÿ
        executor_instance = Mock()
        mock_executor.return_value.__enter__.return_value = executor_instance

        # æ¨¡æ‹Ÿ future çš„ result
        future_success = Mock()
        future_success.result.return_value = (True, "æˆåŠŸ: script1.sh")

        future_failed = Mock()
        future_failed.result.return_value = (False, "å¤±è´¥: script2.sh")

        # mock submit() è¿”å› future
        executor_instance.submit.side_effect = [future_success, future_failed]

        # mock as_completed
        with patch("concurrent.futures.as_completed") as mock_as_completed:
            mock_as_completed.return_value = [future_success, future_failed]
            mock_tqdm.return_value = [future_success, future_failed]

            result = ScriptRunner.run_scripts_in_parallel(Path("."))

        assert result["success"] == 1
        assert result["failed"] == 1


class TestWriteNextflowInput:
    """æµ‹è¯•write_nextflow_inputå‡½æ•°"""

    def setup_method(self):
        """æ¯ä¸ªæµ‹è¯•æ–¹æ³•å‰çš„è®¾ç½®"""
        self.temp_dir = Path(tempfile.mkdtemp())

    def teardown_method(self):
        """æ¯ä¸ªæµ‹è¯•æ–¹æ³•åçš„æ¸…ç†"""
        import shutil

        shutil.rmtree(self.temp_dir, ignore_errors=True)

    def test_write_nextflow_input_empty_df(self):
        """æµ‹è¯•ç©ºæ•°æ®æ¡†"""
        empty_df = pd.DataFrame()

        result = write_nextflow_input(empty_df, self.temp_dir)

        assert result is None

    @patch("fq.project_fq.ScriptRunner.run_scripts_in_parallel")
    def test_write_nextflow_input_success(self, mock_run_scripts):
        """æµ‹è¯•æˆåŠŸå†™å…¥Nextflowè¾“å…¥"""
        # å‡†å¤‡æµ‹è¯•æ•°æ®
        test_df = pd.DataFrame(
            {
                "sample_id": ["SAMPLE1", "SAMPLE1", "SAMPLE2"],
                "read_type": ["R1", "R2", "R1"],
                "path": [
                    "/path/file1_R1.fq.gz",
                    "/path/file1_R2.fq.gz",
                    "/path/file2_R1.fq.gz",
                ],
            }
        )

        mock_run_scripts.return_value = {"success": 2, "failed": 0}

        result = write_nextflow_input(test_df, self.temp_dir)

        assert result is not None
        assert result["success"] == 2
        assert result["failed"] == 0

        # æ£€æŸ¥è„šæœ¬ç›®å½•æ˜¯å¦åˆ›å»º
        scripts_dir = self.temp_dir / "scripts"
        assert scripts_dir.exists()

        mock_run_scripts.assert_called_once()

    def test_write_nextflow_input_with_na_paths(self):
        """æµ‹è¯•åŒ…å«NAè·¯å¾„çš„æ•°æ®"""
        test_df = pd.DataFrame(
            {
                "sample_id": ["SAMPLE1", "SAMPLE1"],
                "read_type": ["R1", "R2"],
                "path": ["/path/file1_R1.fq.gz", None],
            }
        )

        result = write_nextflow_input(test_df, self.temp_dir)

        # åº”è¯¥åªç”Ÿæˆä¸€ä¸ªè„šæœ¬æ–‡ä»¶
        scripts_dir = self.temp_dir / "scripts"
        if scripts_dir.exists():
            scripts = list(scripts_dir.glob("*.sh"))
            assert len(scripts) <= 1


class TestValidateSampleInfo:
    """æµ‹è¯•validate_sample_infoå‡½æ•°"""

    def test_validate_sample_info_valid(self):
        """æµ‹è¯•æœ‰æ•ˆçš„æ ·å“ä¿¡æ¯"""
        valid_df = pd.DataFrame(
            {
                "libid": ["LIB001", "LIB002"],
                "sample_id": ["SAMPLE1", "SAMPLE2"],
                "dir_name": ["dir1", "dir2"],
                "extra_col": ["extra1", "extra2"],
            }
        )

        result = validate_sample_info(valid_df)

        assert isinstance(result, pd.DataFrame)
        assert len(result) == 2

    def test_validate_sample_info_missing_columns(self):
        """æµ‹è¯•ç¼ºå°‘å¿…è¦åˆ—"""
        invalid_df = pd.DataFrame(
            {
                "libid": ["LIB001"],
                "sample_id": ["SAMPLE1"],
                # ç¼ºå°‘ dir_name åˆ—
            }
        )

        with pytest.raises(ValueError, match="æ ·å“ä¿¡æ¯æ–‡ä»¶ç¼ºå°‘å¿…è¦åˆ—"):
            validate_sample_info(invalid_df)

    def test_validate_sample_info_duplicates(self):
        """æµ‹è¯•å»é‡åŠŸèƒ½"""
        df_with_duplicates = pd.DataFrame(
            {
                "libid": ["LIB001", "LIB001", "LIB002"],
                "sample_id": ["SAMPLE1", "SAMPLE1", "SAMPLE2"],
                "dir_name": ["dir1", "dir1", "dir2"],
            }
        )

        result = validate_sample_info(df_with_duplicates)

        assert len(result) == 2  # åº”è¯¥å»é™¤ä¸€ä¸ªé‡å¤è¡Œ

    def test_validate_sample_info_with_nulls(self):
        """æµ‹è¯•åŒ…å«ç©ºå€¼çš„æ•°æ®"""
        df_with_nulls = pd.DataFrame(
            {
                "libid": ["LIB001", None],
                "sample_id": ["SAMPLE1", "SAMPLE2"],
                "dir_name": ["dir1", "dir2"],
            }
        )

        # åº”è¯¥èƒ½å¤Ÿå¤„ç†ç©ºå€¼è€Œä¸æŠ›å‡ºå¼‚å¸¸
        result = validate_sample_info(df_with_nulls)
        assert isinstance(result, pd.DataFrame)


class TestLogStatistics:
    """æµ‹è¯•log_statisticså‡½æ•°"""

    @patch("fq.project_fq.logger")
    def test_log_statistics_empty_df(self, mock_logger):
        """æµ‹è¯•ç©ºæ•°æ®æ¡†çš„ç»Ÿè®¡"""
        empty_df = pd.DataFrame()

        log_statistics(empty_df)

        mock_logger.error.assert_called_with("æ•°æ®æ¡†ä¸ºç©º")

    @patch("fq.project_fq.logger")
    def test_log_statistics_complete_data(self, mock_logger):
        """æµ‹è¯•å®Œæ•´æ•°æ®çš„ç»Ÿè®¡"""
        complete_df = pd.DataFrame(
            {
                "sample_id": ["SAMPLE1", "SAMPLE1", "SAMPLE2"],
                "libid": ["LIB001", "LIB002", "LIB003"],
                "path": ["/path1", "/path2", "/path3"],
            }
        )

        log_statistics(complete_df)

        # æ£€æŸ¥æ˜¯å¦è®°å½•äº†æˆåŠŸä¿¡æ¯
        mock_logger.success.assert_called_with("æ‰€æœ‰æ ·å“æ•°æ®å·²æ‰¾åˆ°")

    @patch("fq.project_fq.logger")
    def test_log_statistics_missing_data(self, mock_logger):
        """æµ‹è¯•ç¼ºå¤±æ•°æ®çš„ç»Ÿè®¡"""
        missing_df = pd.DataFrame(
            {
                "sample_id": ["SAMPLE1", "SAMPLE2"],
                "libid": ["LIB001", "LIB002"],
                "path": ["/path1", None],
            }
        )

        log_statistics(missing_df)

        # æ£€æŸ¥æ˜¯å¦è®°å½•äº†é”™è¯¯ä¿¡æ¯
        mock_logger.error.assert_called()


class TestConstants:
    """æµ‹è¯•å¸¸é‡å®šä¹‰"""

    def test_fastq_extensions(self):
        """æµ‹è¯•FASTQæ‰©å±•åå¸¸é‡"""
        assert "*.fastq.gz" in FASTQ_EXTENSIONS
        assert "*.fq.gz" in FASTQ_EXTENSIONS
        assert len(FASTQ_EXTENSIONS) == 2

    def test_read_type_patterns(self):
        """æµ‹è¯•è¯»å–ç±»å‹æ¨¡å¼å¸¸é‡"""
        assert READ_TYPE_PATTERNS["combined_R1.fastq.gz"] == "R1"
        assert READ_TYPE_PATTERNS["combined_R2.fastq.gz"] == "R2"
        assert READ_TYPE_PATTERNS["_R1.fastq.gz"] == "R1"
        assert READ_TYPE_PATTERNS["_R2.fastq.gz"] == "R2"
        assert READ_TYPE_PATTERNS["_1.fastq.gz"] == "R1"
        assert READ_TYPE_PATTERNS["_2.fastq.gz"] == "R2"


# é›†æˆæµ‹è¯•
class TestIntegration:
    """é›†æˆæµ‹è¯•"""

    def setup_method(self):
        """æ¯ä¸ªæµ‹è¯•æ–¹æ³•å‰çš„è®¾ç½®"""
        self.temp_dir = Path(tempfile.mkdtemp())
        self.processor = FastqProcessor(self.temp_dir)

    def teardown_method(self):
        """æ¯ä¸ªæµ‹è¯•æ–¹æ³•åçš„æ¸…ç†"""
        import shutil

        shutil.rmtree(self.temp_dir, ignore_errors=True)

    @patch("pathlib.Path.glob")
    @patch("pandas.DataFrame.to_csv")
    def test_full_workflow_mock(self, mock_to_csv, mock_glob):
        """æµ‹è¯•å®Œæ•´å·¥ä½œæµç¨‹ï¼ˆä½¿ç”¨mockï¼‰"""
        # æ¨¡æ‹Ÿæ ·å“ä¿¡æ¯
        sample_df = pd.DataFrame(
            {
                "libid": ["LIB001", "LIB002"],
                "sample_id": ["SAMPLE1", "SAMPLE2"],
                "dir_name": ["tcwl-test1", "tcwl-test2"],
            }
        )

        # æ¨¡æ‹Ÿç›®å½•ç»“æ„
        mock_date_dir = Mock()
        mock_date_dir.is_dir.return_value = True
        mock_tcwl_dir = Mock()
        mock_tcwl_dir.name = "tcwl-test1"
        mock_date_dir.glob.return_value = [mock_tcwl_dir]
        mock_glob.return_value = [mock_date_dir]

        # æ¨¡æ‹Ÿé…ç½®åŠ è½½
        with patch.object(self.processor, "read_or_build_config") as mock_read_config:
            mock_read_config.return_value = pd.DataFrame(
                {
                    "libid": ["LIB001"],
                    "read_type": ["R1"],
                    "path": ["/path/to/file.fastq.gz"],
                    "dir_name": ["tcwl-test1"],
                }
            )

            # æ‰§è¡Œé…ç½®åŠ è½½
            result = self.processor.load_config(sample_df["dir_name"].unique())

            # éªŒè¯ç»“æœ
            assert isinstance(result, pd.DataFrame)
            assert len(result) > 0

            # éªŒè¯åˆå¹¶æ“ä½œ
            merged_df = sample_df.merge(result, on="libid", how="left")
            assert "path" in merged_df.columns


# æ€§èƒ½æµ‹è¯•
class TestPerformance:
    """æ€§èƒ½æµ‹è¯•"""

    def test_large_dataframe_processing(self):
        """æµ‹è¯•å¤§æ•°æ®æ¡†å¤„ç†æ€§èƒ½"""
        # åˆ›å»ºå¤§æ•°æ®æ¡†
        large_df = pd.DataFrame(
            {
                "libid": [f"LIB{i:06d}" for i in range(1000)],
                "sample_id": [f"SAMPLE{i:06d}" for i in range(1000)],
                "dir_name": [f"dir{i}" for i in range(1000)],
            }
        )

        # æµ‹è¯•éªŒè¯å‡½æ•°çš„æ€§èƒ½
        import time

        start_time = time.time()

        result = validate_sample_info(large_df)

        end_time = time.time()
        processing_time = end_time - start_time

        # éªŒè¯ç»“æœ
        assert len(result) == 1000
        assert processing_time < 1.0  # åº”è¯¥åœ¨1ç§’å†…å®Œæˆ


# å‚æ•°åŒ–æµ‹è¯•
class TestParametrized:
    """å‚æ•°åŒ–æµ‹è¯•"""

    @pytest.mark.parametrize(
        "filename,expected",
        [
            ("sample_combined_R1.fastq.gz", "R1"),
            ("sample_combined_R2.fastq.gz", "R2"),
            ("sample_R1.fastq.gz", "R1"),
            ("sample_R2.fastq.gz", "R2"),
            ("sample_1.fastq.gz", "R1"),
            ("sample_2.fastq.gz", "R2"),
            ("sample_unknown.fastq.gz", None),
            ("sample.txt", None),
        ],
    )
    def test_determine_read_type_parametrized(self, filename, expected):
        """å‚æ•°åŒ–æµ‹è¯•è¯»å–ç±»å‹è¯†åˆ«"""
        temp_dir = Path(tempfile.mkdtemp())
        processor = FastqProcessor(temp_dir)

        result = processor._determine_read_type(filename)
        assert result == expected

        # æ¸…ç†
        import shutil

        shutil.rmtree(temp_dir, ignore_errors=True)

    @pytest.mark.parametrize(
        "input_files,expected_command_type",
        [
            (["/path/file1.fastq.gz"], "cp"),
            (["/path/file1.fastq.gz", "/path/file2.fastq.gz"], "cat"),
            (["/path/f1.fastq.gz", "/path/f2.fastq.gz", "/path/f3.fastq.gz"], "cat"),
        ],
    )
    def test_merge_command_parametrized(self, input_files, expected_command_type):
        """å‚æ•°åŒ–æµ‹è¯•åˆå¹¶å‘½ä»¤ç”Ÿæˆ"""
        output_name = "output.fastq.gz"

        result = ScriptRunner.merge_or_link_command(input_files, output_name)

        assert result.startswith(expected_command_type)
        assert output_name in result


# é”™è¯¯å¤„ç†æµ‹è¯•
class TestErrorHandling:
    """é”™è¯¯å¤„ç†æµ‹è¯•"""

    def test_file_permission_error(self):
        """æµ‹è¯•æ–‡ä»¶æƒé™é”™è¯¯å¤„ç†"""
        temp_dir = Path(tempfile.mkdtemp())
        processor = FastqProcessor(temp_dir)

        # æ¨¡æ‹Ÿæƒé™é”™è¯¯
        with patch("pathlib.Path.glob") as mock_glob:
            mock_glob.side_effect = PermissionError("Permission denied")

            result = processor.build_libid_fastq_map(temp_dir)

            # åº”è¯¥è¿”å›ç©ºçš„DataFrameè€Œä¸æ˜¯æŠ›å‡ºå¼‚å¸¸
            assert isinstance(result, pd.DataFrame)
            assert len(result) == 0

        # æ¸…ç†
        import shutil

        shutil.rmtree(temp_dir, ignore_errors=True)

    def test_malformed_data_handling(self):
        """æµ‹è¯•æ ¼å¼é”™è¯¯çš„æ•°æ®å¤„ç†"""
        malformed_df = pd.DataFrame(
            {
                "libid": ["LIB001", "LIB002", ""],
                "sample_id": ["SAMPLE1", "", "SAMPLE3"],
                "dir_name": ["dir1", "dir2", "dir3"],
            }
        )

        # åº”è¯¥èƒ½å¤Ÿå¤„ç†è€Œä¸æŠ›å‡ºå¼‚å¸¸
        result = validate_sample_info(malformed_df)
        assert isinstance(result, pd.DataFrame)


if __name__ == "__main__":
    # è¿è¡Œæµ‹è¯•çš„ç¤ºä¾‹å‘½ä»¤
    # pytest test_fastq_processor.py -v
    # pytest test_fastq_processor.py::TestFastqProcessor::test_init_valid_directory -v
    # pytest test_fastq_processor.py -k "test_determine_read_type" -v
    # pytest test_fastq_processor.py --cov=fastq_processor --cov-report=html
    pass
